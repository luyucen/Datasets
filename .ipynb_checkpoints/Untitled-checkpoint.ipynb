{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'/home/cly/python_projects/image_segmentation/1obj/114591144943/src_bw/114591144943.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/114591144943/human_seg/114591144943_11.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/114591144943/human_seg/114591144943_10.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/114591144943/human_seg/114591144943_12.png']\n",
      "[b'/home/cly/python_projects/image_segmentation/1obj/bbmf_lancaster_july_06/src_bw/bbmf_lancaster_july_06.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/bbmf_lancaster_july_06/human_seg/bbmf_lancaster_july_06_14.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/bbmf_lancaster_july_06/human_seg/bbmf_lancaster_july_06_13.png'\n",
      " b'/home/cly/python_projects/image_segmentation/1obj/bbmf_lancaster_july_06/human_seg/bbmf_lancaster_july_06_15.png']\n",
      "70\n",
      "15\n",
      "Image shape:  (64, 64, 1)\n",
      "Mask shape:  (64, 64, 1)\n",
      "Image 0.7048426\n",
      "0.490635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image as Image\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "\n",
    "# In Weizmann dataset, there are totally 100 images. \n",
    "# Image width is fixed at 300 but image height varies from 125 to 465.\n",
    "# Here we will resize all images to a fixed size \n",
    "img_width = 64\n",
    "img_height = 64\n",
    "batch_size = 8\n",
    "\n",
    "data_dir = pathlib.Path('/home/cly/python_projects/image_segmentation/1obj')\n",
    "filenames = list(data_dir.glob('*/src_bw/*'))\n",
    "image_count = len(filenames)\n",
    "\n",
    "# Each tuple consists of the file path of an image and its three segmentation references. \n",
    "def file_paths(f):\n",
    "  segs = list(f.parents[1].glob('human_seg/*.png'))\n",
    "  return (str(f), str(segs[0]), str(segs[1]), str(segs[2]))\n",
    "\n",
    "filename_tuples = [file_paths(f) for f in filenames]\n",
    "\n",
    "list_ds = tf.data.Dataset.from_tensor_slices(filename_tuples)\n",
    "\n",
    "for f in list_ds.take(2):\n",
    "  print(f.numpy())\n",
    "\n",
    "# split test, validation, and training data\n",
    "val_size = int(image_count * 0.3)\n",
    "test_size = int(val_size * 0.5)\n",
    "\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "val_ds = val_ds.skip(test_size)\n",
    "test_ds = val_ds.take(val_size - test_size)\n",
    "\n",
    "train_ds = train_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())\n",
    "\n",
    "def initializeState(img_height, img_width):\n",
    "  center1 = int(img_height/2)\n",
    "  center2 = int(img_width/2)\n",
    "  r = min(img_height, img_width)/3\n",
    "  r2 = r**2\n",
    "  a = np.zeros((img_height, img_width, 1))\n",
    "  for i in range(img_height):\n",
    "    for j in range(img_width):\n",
    "      a[i, j, 0] = float((i-center1)**2 + (j-center2)**2<r2)\n",
    "  return a  \n",
    "    \n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor of shape [height, width, channels]\n",
    "  img = tf.image.decode_png(img, channels=1)\n",
    "  # resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width], method='nearest')\n",
    "\n",
    "def decode_seg(seg):\n",
    "  # segmentation is an RGB image with object marked with red color (255, 0, 0)\n",
    "  seg = tf.image.decode_png(seg, channels=3)\n",
    "  # convert the image to a mask\n",
    "  mask = tf.cast(seg[:,:,0:1]==255, dtype=tf.float32)*tf.cast(seg[:,:,1:2]==0, dtype=tf.float32)*tf.cast(seg[:,:,2:]==0, dtype=tf.float32)\n",
    "  return tf.image.resize(mask, [img_height, img_width], method='nearest')\n",
    "\n",
    "def process_path(paths):\n",
    "  img_path = paths[0]\n",
    "  seg_path = paths[1]\n",
    "  if tf.random.uniform(())>0.66:\n",
    "    seg_path = paths[2]\n",
    "  elif tf.random.uniform(())>0.5:\n",
    "    seg_path = paths[3]\n",
    "  # load the raw data from the file as a string\n",
    "  img_string = tf.io.read_file(img_path)\n",
    "  seg_string = tf.io.read_file(seg_path)\n",
    "  img = decode_img(img_string)\n",
    "  mask = decode_seg(seg_string)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  return img, mask\n",
    "\n",
    "def augment(paths):\n",
    "  img, mask = process_path(paths)\n",
    "  # Cast and normalize the image to [0,1]\n",
    "  img = tf.image.random_brightness(img, max_delta=0.5) # Random brightness\n",
    "  img = tf.image.random_contrast(img, 0.2, 0.5) # Random contrast\n",
    "  \n",
    "  # Filp the image and the mask together\n",
    "  # It seems there is no random rotation in tensorflow?\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    img = tf.image.flip_up_down(img)\n",
    "    mask = tf.image.flip_up_down(mask)\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    mask = tf.image.flip_left_right(mask)\n",
    "  return img, mask\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "for image, mask in train_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Mask shape: \", mask.numpy().shape)\n",
    "  print(\"Image\", np.max(image.numpy()))\n",
    "  print(np.min(image.numpy()))\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "\n",
    "# Visualize data\n",
    "image_batch, mask_batch = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):\n",
    "  ax = plt.subplot(4, 2, 2*i + 1)\n",
    "  plt.imshow(image_batch[i][:,:,0].numpy(), cmap='gray')\n",
    "  plt.axis(\"off\")\n",
    "  mask = mask_batch[i][:,:,0].numpy().astype(\"uint8\")\n",
    "  ax = plt.subplot(4, 2, 2*i+2)\n",
    "  plt.imshow(mask, cmap='gray')\n",
    "  plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fidelityTerm(keras.layers.Layer):\n",
    "  def __init__(self, img_size, threshold=0.5):\n",
    "    super(fidelityTerm, self).__init__()\n",
    "    self.Ug = self.add_weight(shape=(img_size, img_size), initializer=tf.random_normal_initializer(mean=1), trainable=True)\n",
    "    self.Wg = self.add_weight(shape=(img_size, img_size), initializer=tf.random_normal_initializer(mean=1), trainable=True)\n",
    "    self.flatten = keras.layers.Flatten()\n",
    "    self.threshold = threshold\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    img = inputs[0]\n",
    "    state = inputs[1]\n",
    "    # c1 = tf.stop_gradient(tf.divide(tf.reduce_sum(img*state, axis=1), tf.reduce_sum(state, axis=1)))\n",
    "    # c2 = tf.stop_gradient(tf.divide(tf.reduce_sum(img*(1-state), axis=1), tf.reduce_sum(1-state, axis=1)))\n",
    "    c1 = tf.stop_gradient(tf.divide(tf.reduce_sum(tf.cast(state>self.threshold, tf.float32)*img, axis=1), tf.reduce_sum(tf.cast(state>0.5, tf.float32), axis=1)+sys.float_info.epsilon))\n",
    "    c2 = tf.stop_gradient(tf.divide(tf.reduce_sum(tf.cast(state<self.threshold, tf.float32)*img, axis=1), tf.reduce_sum(tf.cast(state<0.5, tf.float32), axis=1)+sys.float_info.epsilon))\n",
    "    c1 = self.flatten(c1)\n",
    "    c2 = self.flatten(c2)\n",
    "    return tf.matmul(tf.math.squared_difference(img, c1), self.Ug) - tf.matmul(tf.math.squared_difference(img, c2), self.Wg)\n",
    "\n",
    "class myModelBlock(keras.layers.Layer):\n",
    "  def __init__(self, img_height, img_width):\n",
    "    super(myModelBlock, self).__init__()\n",
    "    self.fidelity = fidelityTerm(img_height*img_width)\n",
    "    self.reshape2D = keras.layers.Reshape((img_height, img_width, 1))\n",
    "    self.conv2D = keras.layers.Conv2D(1, 3, padding='same')\n",
    "    self.flatten = keras.layers.Flatten()\n",
    "    self.dense = keras.layers.Dense(img_height*img_width)\n",
    "    self.activation = keras.layers.Activation(activation=tf.keras.activations.tanh)\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    state = inputs[1]\n",
    "    x = self.fidelity(inputs)\n",
    "    y = self.reshape2D(state)\n",
    "    y = self.conv2D(1-2*y)\n",
    "    y = self.flatten(y)\n",
    "    y = self.dense(-x-y)\n",
    "    return [inputs[0], 0.5+0.5*self.activation(y)]\n",
    "\n",
    "class myModel(keras.Model):\n",
    "  def __init__(self, img_height, img_width, state0):\n",
    "    super(myModel, self).__init__()\n",
    "    self.state0 = state0\n",
    "    self.flatten = keras.layers.Flatten()\n",
    "    self.block1 = myModelBlock(img_height, img_width)\n",
    "    self.block2 = myModelBlock(img_height, img_width)\n",
    "    self.block3 = myModelBlock(img_height, img_width)\n",
    "    self.reshape = keras.layers.Reshape((img_height, img_width, 1))\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.flatten(inputs)\n",
    "    x = self.block1([x, tf.reshape(state0, [1, -1])])\n",
    "    x = self.block2(x)\n",
    "    x = self.block3(x)[1]\n",
    "    return self.reshape(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fidelityTerm_Heaviside(keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    \n",
    "class levelsetBlock(keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(levelsetBlock, self).__init__()\n",
    "  def call(self, inputs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer my_model_block_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "9/9 [==============================] - 6s 664ms/step - loss: 1.1032 - val_loss: 0.8978\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 6s 651ms/step - loss: 0.7651 - val_loss: 1.1560\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 6s 651ms/step - loss: 0.5988 - val_loss: 1.2584\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 6s 651ms/step - loss: 0.5658 - val_loss: 1.7340\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 6s 649ms/step - loss: 0.4960 - val_loss: 1.6567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2286a22e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state0 = initializeState(img_height, img_width)\n",
    "model = myModel(img_height, img_width, state0)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss=keras.losses.BinaryCrossentropy())\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
